<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Responsible AI international community to reduce bias in AI music generation and analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="/assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">

		<!-- Header -->
			<header id="header">
				<h0><strong>Music<br>RAI</strong></h0><br />
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">

						<!--<h1>Duxianqin Workshop 2019</h1>-->
						</header>

<a id="projectinfo"><h1>Artistic mini-project</h1></a>

            <p>Deadline for Expression of Interest (EoI): Mon 28th Oct 2024 <br/>
            Announcement of awards: Wed 6th November 2024<br/>
            Projects to be completed by: Mon 6th January 2025<br/>
            Award: Â£5,000</p>
            <h3>About</h3>
            <p>We will commission 3 speculative artistic mini-projects to use AI to create music with genres that are currently marginalised by main-stream AI models. The aim of these mini-projects is to create impact and interest in Responsible AI (RAI) concerns of bias in AI models. These mini-projects will use AI tools such as low-resource AI models with small datasets and will be supported by the project team or industry partners where needed. The mini-projects will showcase the challenges of bias in AI and how RAI techniques can be used to address them.</p>
            <h3>Requirements</h3>
            <span>The deliverable of the mini-projects must include:</span>
            <ul>
              <li>A piece or pieces of music created using AI with small music or audio dataset(s) that are currently marginalised by main-stream AI models. This could be in the form of an audio file, a video, an interactive piece, or other format by agreement with the organisers. The audio should be high quality and typical EP length as agreed with the organisers, e.g. equivalent to approximately 15 minutes of music and up to 6 pieces of music. Preferably the composition would use datasets and AI models made available by the research project partners. The composition should somehow highlight or touch on the bias of current large AI models. Please contact the organisers if you want to discuss your ideas and these requirements.</li>
              <li>A short video (5 minutes) describing the composition process and use of AI and small datasets in the composition highlighting how less represented music genres have been used in music generation with AI. The video must be produced to a professional quality.</li>
              <li>A short video (3 to 5 minutes) to promote and exhibit the music piece(s) e.g. for use in a video loop in a hybrid exhibition. The video must be produced to a professional quality.</li>
            </ul>
            <p>The recipient of the award must commit to attend an exhibition of the mini-projects and introduce their mini-project. This exhibition is likely to take place in January 2025. Note that Intellectual Property Rights of the created pieces will belong to UAL and the recipient can use the pieces for non-commercial purposes
            </p>
            <h3>How to apply</h3>
            <span>To apply, please fill in <a href="https://forms.office.com/e/ffdTNrAvm4" target="_blank">this form</a>.</span>
            <span>You will be asked to provide:</span>
            <ul>
              <li>A short statement describing the proposed mini-project and how it meets the aims,</li>
              <li>A portfolio of up to 4 previous audio projects, e.g. links to web pages like SoundCloud,</li>
              <li>A link to your website and social media profiles.</li>
            </ul>
            <h3>Contact us</h3>
            <p>If you have any questions about the application process, please contact the organisers: <a href="mailto:cci.musicrai@arts.ac.uk">cci.musicrai@arts.ac.uk</a></p>

<h3>Frequently Asked Questions</h3>

<p><b>Question:</b>
Can a team apply?
<br><b>Answer:</b>
Yes. Please note that the award is per mini-project, not per person.
</p>

<p><b>Question:</b>
Is there a specific AI model we should use or consider? For example, can we use existing models like IRCAM RAVE, but create our own datasets?
<br><b>Answer:</b>
We do not require use of a specific AI model. The aim of the mini-project is to show the potential of low-resource AI models and small datasets - to use models that are efficient, real-time if possible, and can produce interesting results even with smaller, custom datasets. Whilst RAVE is a deep-learning model it is still acceptable as one of the few real-time models that is also open-source and amenable to use with small datasets.
</p>

<p><b>Question:</b>
Is the duration negotiable?
<br><b>Answer:</b>
Yes. Please make clear what duration you propose in your application.	
</p>


<p><b>Question:</b>
Can I create a multichannel version of the piece, or should it be stereo only?
<br><b>Answer:</b>
We prefer stereo pieces that would be more widely consumable than multichannel versions. If you do propose a multichannel version then please also produce a stereo version for wide consumption.	
</p>

<p><b>Question:</b>
Can a UAL member of staff or student apply?
<br><b>Answer:</b>
Yes. Please note that members of the project team and project partners cannot apply.
</p>

<p><b>Question:</b>
Can the presentation of the work in the January exhibition be audivisual?
<br><b>Answer:</b>
Yes.
</p>

<p><b>Question:</b>
The call asks for us to preferably use datasets and AI models made available by the research project partners, but waht are these?
	<br><b>Answer:</b>
	The research partners include Music Hackspace (UK), DAACI (UK), Steinberg (Germany), Bela (UK), and also the academic partners Prof. Zijin Li (Central Conservatory of Music, China; CCoM), Dr. Nuno Correia (Tallinn University, Estonia; TU), Dr. Alex Lerch (Georgia Tech, USA; GT), Prof. Sid Fels (University of British Columbia, Canada; UBC), Dr. Gabriel Vigliensoni (Concordia University, Canada; CU), Dr. Andrei Coronel and Dr. Raphael Alampay (Ateneo de Manila University, Philippines; AdMU), and Prof. Rikard Lindell (Dalarna University, Sweden; DU).

We don't have a list of datasets or AI models from the partners, so if you are interested to explore these possible resources then please review the case studies from the workshops in which partners talk about their work:
<a href = "https://music-rai.github.io">https://music-rai.github.io</a>
	</p>

<!--
<p><b>Question:</b>

<br><b>Answer:</b>

</p>
-->

<!--
<dl>
	<dt>Question:</dt>
	<dd>Can a team apply?</dd>
	<dt>Answer:</dt>
	<dd>Yes. The award is per mini-project, not per person.</dd>
</dl>

<dl></dl>
	<dt>Question:</dt>
	<dd>Can a UAL member of staff or student apply?</dd>
	<dt>Answer:</dt>
	<dd>Yes. Only members of the project team or partners cannot apply.</dd>
</dl>-->



<a id="projectinfo"><h1>About the MusicRAI Research Project</h1></a>
						<p>This 12 month project <strong>"Responsible AI international community to reduce bias in AI music generation and analysis"</strong> will build an international community to address Responsible AI (RAI) challenges of bias in AI music generation and analysis.</p>
						<p>The aim of the project is to explore ways to tackle current over-reliance on huge training datasets for deep learning leads to AI models biased towards Western classical and pop music and marginalises other music genres. We will bring together an international and interdisciplinary team of researchers, musicians, and industry experts to make available AI tools, expertise, and datasets which improve access to marginalised music genres. This will directly benefit musicians and audiences engaging with a wider range of musical genres and benefits creative industries by offering new forms of music consumption.</p>

<p>For more information about the project and the context of this call please see the project webpage: <a href = "http://musicrai.org">musicrai.org</a></p>

						<h1>Funding</h1>

						<p>Funded by <a href = "https://www.rai.ac.uk">Responsible Artificial Intelligence (RAI) UK</a> <a href = "https://www.rai.ac.uk/international-partnerships">International Partnerships</a> (UKRI EPSRC grant reference EP/Y009800/1)</p>


					</section>

<hr>

				       <h6>Template: <a href="http://html5up.net/">HTML5 UP</a> </h6>

			</div>

		<!-- Scripts -->
			<script src="/assets/js/jquery.min.js"></script>
			<script src="/assets/js/jquery.poptrox.min.js"></script>
			<script src="/assets/js/skel.min.js"></script>
			<script src="/assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="/assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="/assets/js/main.js"></script>
	</body>
</html>
